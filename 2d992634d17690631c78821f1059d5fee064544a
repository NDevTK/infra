{
  "comments": [
    {
      "key": {
        "uuid": "652f6c59_28354138",
        "filename": "infra/dataflow/events/cq_attempts.py",
        "patchSetId": 1
      },
      "lineNbr": 6,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-03T14:32:51Z",
      "side": 1,
      "message": "nit: Why is this necessary? Although BigQuery makes it easier to make changes to proto and rename enum values, I\u0027d not expect the value of this constant to change all that frequently, thus would suggest using it directly.",
      "range": {
        "startLine": 6,
        "startChar": 0,
        "endLine": 6,
        "endChar": 34
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a531301e_e7576747",
        "filename": "infra/dataflow/events/cq_attempts.py",
        "patchSetId": 1
      },
      "lineNbr": 8,
      "author": {
        "id": 1002100
      },
      "writtenOn": "2017-06-29T22:34:30Z",
      "side": 1,
      "message": "At some point we\u0027ll have to consider if these class definitions should be shared and imported, or defined in their pipeline files. It depends on how many different pipelines will be writing the same objects to the same tables, and whether anything will be reading objects from those tables. I\u0027m not sure what that\u0027s going to look like, but think about it.",
      "range": {
        "startLine": 8,
        "startChar": 0,
        "endLine": 8,
        "endChar": 24
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "c4052c9f_4915b787",
        "filename": "infra/dataflow/events/cq_attempts.py",
        "patchSetId": 1
      },
      "lineNbr": 30,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-03T14:32:51Z",
      "side": 1,
      "message": "nit: s/i/input_rows/",
      "range": {
        "startLine": 30,
        "startChar": 35,
        "endLine": 30,
        "endChar": 36
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "516cdc12_8e43ae4d",
        "filename": "infra/dataflow/events/cq_attempts.py",
        "patchSetId": 1
      },
      "lineNbr": 30,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-06T08:14:39Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "c4052c9f_4915b787",
      "range": {
        "startLine": 30,
        "startChar": 35,
        "endLine": 30,
        "endChar": 36
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "357a0499_59559632",
        "filename": "infra/dataflow/events/cq_attempts.py",
        "patchSetId": 1
      },
      "lineNbr": 42,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-03T14:32:51Z",
      "side": 1,
      "message": "Why is this check needed? We can just override attempt_start_msec since they supposed to be the same for all rows. Perhaps also add an assert\n\n  assert (accumulator.attempt_start_msec is None or\n          accumulator.attempt_start_msec \u003d\u003d attempt_start_msec)",
      "range": {
        "startLine": 42,
        "startChar": 6,
        "endLine": 42,
        "endChar": 48
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "b86e6019_3d97c9e8",
        "filename": "infra/dataflow/events/cq_attempts.py",
        "patchSetId": 1
      },
      "lineNbr": 42,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-06T08:14:39Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "357a0499_59559632",
      "range": {
        "startLine": 42,
        "startChar": 6,
        "endLine": 42,
        "endChar": 48
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "c8dda8d9_4a818051",
        "filename": "infra/dataflow/events/cq_attempts.py",
        "patchSetId": 1
      },
      "lineNbr": 62,
      "author": {
        "id": 1002100
      },
      "writtenOn": "2017-06-29T22:34:30Z",
      "side": 1,
      "message": "This is a case where a library might help a little. If we had a \"InfraBigtableObject\" class that CQAttempt and everything like it inherited from, then those classes could all implement their own extract_output function. Might one of those classes ever want to store data fields on itself that shouldn\u0027t get written to the table? Then we wouldn\u0027t want to use __dict__ in that case.",
      "range": {
        "startLine": 61,
        "startChar": 0,
        "endLine": 62,
        "endChar": 21
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "885aa204_bea094e3",
        "filename": "infra/dataflow/events/cq_attempts.py",
        "patchSetId": 1
      },
      "lineNbr": 79,
      "author": {
        "id": 1002100
      },
      "writtenOn": "2017-06-29T22:34:30Z",
      "side": 1,
      "message": "This whole stanza is straightforward and simple -- huzzah for just using the beam api and not requiring chrome infra folks from knowing another library -- but it is also *flexible*. There\u0027s an argument to be made that the way to keep these dataflow pipelines \"simple\" is not to simply expose the beam API, but rather to expose a *very narrow subset* of the beam API.\n\nFor example, this could be my_dataflow_lib.Transform(p, q, CombineEventsToAttempt, \u0027cq_attempts\u0027). All dataflows take a single query, a single pipeline, a single CombineFn, and a single output, and then just run them. Or something like that.\n\nOf course, that requirement may not last very long. It\u0027ll be hard to know until we have two or three real pipelines and see what commonalities there are. If we enforce a very strict subset right now, those other useful pipelines might be harder to create. If we don\u0027t enforce a very strict subset right now, those other pipelines might do crazy stuff. It\u0027s up to you to decide which way to go, but it should be a carefully considered decision.",
      "range": {
        "startLine": 70,
        "startChar": 2,
        "endLine": 79,
        "endChar": 72
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ae119373_d4c79573",
        "filename": "infra/dataflow/events/cq_attempts_test.py",
        "patchSetId": 1
      },
      "lineNbr": 4,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-03T14:32:51Z",
      "side": 1,
      "message": "Hooray! Tests!",
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "7f981dcf_f7330a26",
        "filename": "infra/dataflow/events/cq_attempts_test.py",
        "patchSetId": 1
      },
      "lineNbr": 30,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-03T14:32:51Z",
      "side": 1,
      "message": "nit: Why not just use self.basic_accumulator below? It\u0027s not that much longer...",
      "range": {
        "startLine": 30,
        "startChar": 4,
        "endLine": 30,
        "endChar": 40
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "23965255_18783a1c",
        "filename": "infra/dataflow/events/cq_attempts_test.py",
        "patchSetId": 1
      },
      "lineNbr": 30,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-06T08:14:39Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "7f981dcf_f7330a26",
      "range": {
        "startLine": 30,
        "startChar": 4,
        "endLine": 30,
        "endChar": 40
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "22b87ca5_f2126fc0",
        "filename": "infra/dataflow/events/cq_attempts_test.py",
        "patchSetId": 1
      },
      "lineNbr": 73,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-03T14:32:51Z",
      "side": 1,
      "message": "Wouldn\u0027t this copy by reference and modify the original object that is also referenced by `accumulator`? Ditto in next test.",
      "range": {
        "startLine": 73,
        "startChar": 4,
        "endLine": 73,
        "endChar": 36
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "e9308f05_3d5abe44",
        "filename": "infra/dataflow/events/cq_attempts_test.py",
        "patchSetId": 1
      },
      "lineNbr": 73,
      "author": {
        "id": 1153089
      },
      "writtenOn": "2017-07-06T08:14:39Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "22b87ca5_f2126fc0",
      "range": {
        "startLine": 73,
        "startChar": 4,
        "endLine": 73,
        "endChar": 36
      },
      "revId": "2d992634d17690631c78821f1059d5fee064544a",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}